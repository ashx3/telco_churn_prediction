{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# preprocessing tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# model building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>tenure_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "      <td>1 - 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "      <td>25 - 36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1 - 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "      <td>37 - 48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1 - 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender SeniorCitizen Partner Dependents PhoneService MultipleLines  \\\n",
       "0  Female            No     Yes         No           No            No   \n",
       "1    Male            No      No         No          Yes            No   \n",
       "2    Male            No      No         No          Yes            No   \n",
       "3    Male            No      No         No           No            No   \n",
       "4  Female            No      No         No          Yes            No   \n",
       "\n",
       "  InternetService OnlineSecurity OnlineBackup DeviceProtection TechSupport  \\\n",
       "0             DSL             No          Yes               No          No   \n",
       "1             DSL            Yes           No              Yes          No   \n",
       "2             DSL            Yes          Yes               No          No   \n",
       "3             DSL            Yes           No              Yes         Yes   \n",
       "4     Fiber optic             No           No               No          No   \n",
       "\n",
       "  StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No              No  Month-to-month              Yes   \n",
       "1          No              No        One year               No   \n",
       "2          No              No  Month-to-month              Yes   \n",
       "3          No              No        One year               No   \n",
       "4          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod  MonthlyCharges  TotalCharges Churn tenure_group  \n",
       "0           Electronic check           29.85         29.85    No       1 - 12  \n",
       "1               Mailed check           56.95       1889.50    No      25 - 36  \n",
       "2               Mailed check           53.85        108.15   Yes       1 - 12  \n",
       "3  Bank transfer (automatic)           42.30       1840.75    No      37 - 48  \n",
       "4           Electronic check           70.70        151.65   Yes       1 - 12  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/tel_churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Splitting the dataset into X and y\n",
    "\n",
    "    X = df.drop('Churn', axis=1)\n",
    "    y = df['Churn']\n",
    "\n",
    "    # train test split\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=100)\n",
    "\n",
    "    # categorical columns\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object' and col != 'Churn']\n",
    "\n",
    "    # numerical columns\n",
    "    num_cols = [col for col in df.columns if df[col].dtype != 'object']\n",
    "\n",
    "    # Dividing the columns into 3 categories;\n",
    "    # standard scaler for numerical columns\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    x_train[num_cols] = ss.fit_transform(x_train[num_cols])\n",
    "    x_test[num_cols] = ss.transform(x_test[num_cols])\n",
    "\n",
    "    with open(\"encoders\\StandardScaler\", \"wb\") as f: \n",
    "        pickle.dump(ss, f)\n",
    "\n",
    "    # label encoder for target variable\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_train_encode = le.fit_transform(y_train)\n",
    "    y_test_encode = le.transform(y_test)\n",
    "\n",
    "    with open('encoders\\Label-Encoder', 'wb') as f:\n",
    "        pickle.dump(le, f)\n",
    "\n",
    "    # one-hot encoding for categorical features\n",
    "\n",
    "    ohe = OneHotEncoder(sparse=False, drop='if_binary')\n",
    "    x_train_ohe = ohe.fit_transform(x_train[cat_cols])\n",
    "    x_test_ohe = ohe.transform(x_test[cat_cols])\n",
    "\n",
    "    with open(\"encoders\\One-Hot-Encoder\", \"wb\") as f: \n",
    "        pickle.dump(ohe, f)\n",
    "\n",
    "    # assigning right column names to cat cols after one-hot encoding\n",
    "    col_ohe = ohe.get_feature_names(cat_cols)\n",
    "\n",
    "    # create df for one hot encoded features\n",
    "    x_train_ohe_df = pd.DataFrame(x_train_ohe, columns = col_ohe, index = x_train.index)\n",
    "    x_test_ohe_df = pd.DataFrame(x_test_ohe, columns = col_ohe, index = x_test.index)\n",
    "\n",
    "    # combine the numerical and encoded features\n",
    "    x_train_encode = pd.concat([x_train.drop(columns=cat_cols), x_train_ohe_df], axis=1)\n",
    "    x_test_encode = pd.concat([x_test.drop(columns=cat_cols), x_test_ohe_df], axis=1)\n",
    "\n",
    "    return x_train_encode, x_test_encode, y_train_encode, y_test_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_encode, x_test_encode, y_train_encode, y_test_encode = preprocess_inputs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree classifier\n",
    "model_dt = DecisionTreeClassifier(criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=6, min_samples_leaf=8, random_state=100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dt.fit(x_train_encode, y_train_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_dt.predict(x_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[901 132]\n",
      " [194 180]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test_encode, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.85      1033\n",
      "           1       0.58      0.48      0.52       374\n",
      "\n",
      "    accuracy                           0.77      1407\n",
      "   macro avg       0.70      0.68      0.69      1407\n",
      "weighted avg       0.76      0.77      0.76      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_encode, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5625,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4130 1495]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_train_encode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy is quite low also keeping in mind that the dataset is quite imbalanced. The accuracy should not be considered as the metrics as the accuracy is cursed in an imbalanced data.\n",
    "- Hence, it is essential to check recall, precision & f1 score for the minority class, and it's quite evident these scores are low as well for the minority class i.e. Churned Customers.\n",
    "- Hence, we shall to scale the classes of the dataset using SMOTE (Upsampling).\n",
    "- But first let's try other as well classifiers before over-sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_pred_list, y_test, plot=True, axis=0, cmap='Blues'):\n",
    "    model_name = []\n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    roc_auc = []\n",
    "\n",
    "    for name, y_pred in y_pred_list.items():\n",
    "        model_name.append(name)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        roc_auc.append(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "        score_list = {\n",
    "          'model':model_name,\n",
    "          'accuracy':accuracy,\n",
    "          'precision':precision,\n",
    "          'recall':recall,\n",
    "          'f1_score':f1,\n",
    "          'roc_auc':roc_auc\n",
    "        }\n",
    "    \n",
    "    score_df = pd.DataFrame(score_list).set_index('model')\n",
    "\n",
    "    if plot:\n",
    "        display(score_df.style.background_gradient(axis=axis, cmap=cmap))\n",
    "\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list ={\n",
    "    'Logistic Regression' :LogisticRegression(max_iter=1000, random_state=100),\n",
    "    'Ridge Classifier' :RidgeClassifier(random_state=100),\n",
    "    'Decision Tree' :DecisionTreeClassifier(random_state=100),\n",
    "    'Random Forest':RandomForestClassifier(random_state=100),\n",
    "    'KNN' :KNeighborsClassifier(),\n",
    "    'SVC' :SVC(random_state=100),\n",
    "    'Neural Network' : MLPClassifier(max_iter=1000, random_state=100),\n",
    "    'Gradient Boosting Classifier':GradientBoostingClassifier(random_state=100),\n",
    "    'AdaBoost Classifier':AdaBoostClassifier(random_state=100),\n",
    "    'CatBoost Classifier':CatBoostClassifier(random_state=100, verbose=False),\n",
    "    'XGBoost':XGBClassifier(random_state=100, use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM':LGBMClassifier(random_state=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = dict()\n",
    "\n",
    "for name, model in model_list.items():\n",
    "  model.fit(x_train_encode, y_train_encode)\n",
    "  y_pred_list[name] = model.predict(x_test_encode)\n",
    "\n",
    "score_smote = get_score(y_pred_list, y_test_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no drastic difference in the scores, now let's try over-sampling techniques to upscale the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling - counts of label '0': 4130\n",
      "Before OverSampling - counts of label '1': 1495 \n",
      "\n",
      "After OverSampling with SMOTE - x_train: (8260, 31)\n",
      "After OverSampling with SMOTE - y_train: (8260,) \n",
      "\n",
      "After OverSampling with SMOTE - counts of label '0': 4130\n",
      "After OverSampling with SMOTE - counts of label '1': 4130\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling - counts of label '0': {}\".format(sum(y_train_encode == 0)))\n",
    "print(\"Before OverSampling - counts of label '1': {} \\n\".format(sum(y_train_encode == 1)))\n",
    "\n",
    "sm = SMOTE(random_state=100)\n",
    "x_train_smote, y_train_smote = sm.fit_resample(x_train_encode, y_train_encode.ravel())\n",
    "\n",
    "print('After OverSampling with SMOTE - x_train: {}'.format(x_train_smote.shape))\n",
    "print('After OverSampling with SMOTE - y_train: {} \\n'.format(y_train_smote.shape))\n",
    "\n",
    "print(\"After OverSampling with SMOTE - counts of label '0': {}\".format(sum(y_train_smote == 0)))\n",
    "print(\"After OverSampling with SMOTE - counts of label '1': {}\".format(sum(y_train_smote == 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using over-sampling only on training set as there might be leakage of information from the test set to training set while training the model. So it is a good measure to not use any sampling techniques on the test set and it also helps in preventing overfitting issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After over-sampling, now let's train the model using Support Vector Machine classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_smote = SVC()\n",
    "model_lr_smote.fit(x_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lr_smote.predict(x_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746268656716418\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, y_test_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.75      0.81      1033\n",
      "           1       0.52      0.73      0.60       374\n",
      "\n",
      "    accuracy                           0.75      1407\n",
      "   macro avg       0.70      0.74      0.71      1407\n",
      "weighted avg       0.79      0.75      0.76      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_encode, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After upscaling, there is not a huge difference overall.\n",
    "- The minority class has a slightly better score than the previous models but not much though, even after upsampling it seems like we need more samples of minority class for the model to perform better.<br>\n",
    "Now let's try other classifiers as well and pick the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = dict()\n",
    "\n",
    "for name, model in model_list.items():\n",
    "  model.fit(x_train_smote, y_train_smote)\n",
    "  y_pred_list[name] = model.predict(x_test_encode)\n",
    "\n",
    "score_smote = get_score(y_pred_list, y_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y_pred_list:\n",
    "    print(i, ':', accuracy_score(y_pred_list[i], y_test_encode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above metrics and scores are not quite as convincing but for now, CatBoost Classifier performs the best comparing to other classifiers, so let's pick it as our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1c65d5626d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cb = CatBoostClassifier(random_state=100, verbose=False)\n",
    "model_cb.fit(x_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cb.predict(x_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931769722814499\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_encode, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pca = pca.fit_transform(x_train_smote)\n",
    "x_test_pca = pca.transform(x_test_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1a8e38591c0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cb_pca = CatBoostClassifier(random_state=100, verbose=False)\n",
    "model_cb_pca.fit(x_train_pca, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_cb_pca.predict(x_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767590618336887\n"
     ]
    }
   ],
   "source": [
    "model_score_pca = model_cb_pca.score(x_test_pca, y_test_encode)\n",
    "print(model_score_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after performing PCA, we couldn't see any better results.<br>\n",
    "Hence, let's finalize the model created by CatBoost Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.sav', 'wb') as f:\n",
    "    pickle.dump(model_cb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.sav', 'rb') as f:\n",
    "    m = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
